CAPITULO 1:
===========

1.1. INTRODUCCION Y DEFINICION DE ESTADISTICA

El término "estadistica" se derivó originalmente del vocablo
"estado", porque ha sido función tradicional de los gobiernos centra-
les llevar registros de población, nacimiento,defunciones, profesiones,
cosechas y muchas otras clases de cosas y actividades.Contar y medir es
tos hechos genera muchas clases de datos numéricos.

La estadística es concebida popularmente como columnas de ci-
fras o gráficas, asociadas generalmente con promedios. Este concepto se
aproxima mucho a la definición tradicional de estadística:la colección,
organización,resumen y presentación de datos numéricos.Actualmente la Es_
tadística es una rama de la matemática aplicada que colecciona, clasifi-
ca y evalúa o analiza datos como base para inferencias o conclusiones vá
lidas, así como para tomar decisiones en base a ese análisis.

Como un procedimiento de toma de decisiones, la Estadística es
de importancia creciente en varios campos, por ejemplo, en la producción
industrial en masa, Medicina Y Biología, Economía, Política, Psicología,
análisis de opinión pública y otras Ciencias Sociales, Agricultura, Meteo_
rología, Física, Química e Ingeniería.

1.2. RELACION ENTRE ESTADISTICA Y PROBABILIDAD

La probabilidad es el estudio de fenómenos puramente aleatorios
mientras que la Estadística se puede describir como la ciencia o el arte
de reunir y analizar datos e inferir consecuencias a partir de estos ele-
mentos. Como el azar afecta tanto a la reunión de datos como a su análi-
sis, y se debe tener en cuenta al hacer inferencias, el tener conocimien-
tos en estadística implica poseer una buena base sobre la teoría de la
probabilidad.

1.3 SINTESIS HISTORICA DE LA ESTADISTICA Y DE LA PROBABILIDAD

La teoría de la Probabilidad tuvo su origen en las apuestas en
juegos de azar; a Girolamo Cardano (1501-15761, físico, astrónomo y materna
tico, se le atribuye la primera discusión sobre probabilidad en su manual
para jugadores; pero fueron Pascal (1623-16621 y Fermat (16001 -1665). al re
dedor de la primera mitad del siglo XVII quienes desarrollaron la Teoría
de la Probabilidad,

Jakob Bernoulli (1654-1705) fue también uno de los primeros que
estudiaron la probabilidad matemática; su nombre va asociado a varios con-
ceptos matemáticos, como los Experimentos de Bernoulli en probabilidad.

La curva normal ha sido de gran importancia en el desarrollo de
la estadística. La ecuación de esta curva fue publicada por primera vez en
1733 por De Moivre. Pero De Moivre no ten.
.dea de su aplicación en obser
vaciones experimentales y su publicación era desconocida hasta que Karl
Pearson la encontró en una Biblioteca en 1924. Sin embargo, esta ecuación
también fue descubierta posteriormente por dos astrónomos y matemáticos:
Laplace (1749-1827) y Gauss (1777-1855) independientemente, hoy en día se
conoce también como la curva de Gauss o campana de Gauss.

En el siglo XIX Charles Lyell encontró aplicación de la Estadís
tica a un problema de Geología.
Entre 1830 y 1833 Lyell publicó tres vo-
lúmenes sobre Geología donde establece la relación entre las rocas tercia-
rias y sus respectivos nombres. El razonamiento de Lyell fue esencialmente
estadístico. Una vez que se establecieron y aceptaron los nombres, el mé-
todo fue casi totalmente olvidado. No han habido geólogos evolucionistas
que investiguen si fueron usadas medidas discretas, implícitas en los nom-
bres, o si usó un proceso continuo y, si podrá ser usado para hacer pre-
dicciones.

Charles Darwin (1809-1882), biólogo, recibió el segundo volumen
de Lyell y se cree que su teoría fue influenciada por este libro. El tra-
bajo de Darwin fue principalmente de naturaleza biométrica o estadística.
También Mendel con su estudio de las plantas híbridas publicado en 1866
tenía un problema de tipo biométrico o estadístico.

Pafhuti Lvovich Chevyshev (1821-1894) contribuyó a la teoría de
la probabilidad con la Desigualdad de Chevyshev, que debido a su generali-
dad resulta ser una herramienta teórica muy importante.

En el siglo XIX la necesidad de una profundización en las bases
de la Estadística se hizo trascendental, Karl Pearson (1857-1936) físico-
matemático inglés, inspirado en Darwin, aplicó sus matemáticas a la evolu-
ción. Pearson, considerado el padre de la Estadística pasó casi medio si-
glo haciendo una profunda investigación en Estadística, asi también fue el
fundador de la revista "Biometrika" y de la Escuela de Estadística en Cam-
bridge, Inglaterra ganando gran ímpetu el estudio de esta materia. A Karl
Pearson se debe el estudio de la bondad de ajuste con la distribución X2 y
el coeficiente de correlación entre dos variables.

Mientras Karl Pearson trabajaba con grandes muestras, la teoría
de las grandes muestras era inadecuada para los investigadores que tenían
que trabajar con pequeñas muestras. Entre ellos estaba W. S. Gosset (1876-
1937), alumno de K. Pearson y científico de la Cervecería "Guinness". Los
conocimientos matemáticos de Gosset mostraron haber sido insuficientes pa-
ra el reto de encontrar distribuciones exactas de la desviación estándar
de la muestra, del cociente de la media y la desviación estándar de una
muestra y del coeficiente de correlación, estadígrafos con los cuales él
comunmente trabajaba. Consecuentemente el recurrió a compilar y computar
las distribuciones de frecuencias empíricas al tomar cartas de un paquete
de cartas barajadas, Los resultados de estos trabajos aparecieron en la re
vista "Biometrika" en 1908 bajo el seudónimo de "student". Hoy en día, la
distribución " t " de estudent es una herramienta básica para los estadísti_
cos y experimentadores y "estudiantizar" es una expresión común en Estadís_
tica. Ahora que el uso de la distribución t de student está mundialmente
difundida es interesante notar que el astrónomo alemán Helmet había obteni
do los mismos resultados teóricamente a principios de 1875.

Ronald Alymer Fisher (1890-1962), especialista inglés en Genéti-
ca y Estadística, fue influenciado por Karl Pearson y Gosset; hizo numero-
sas e importantes contribuciones a la Estadística, precisó métodos estádis_
ticos para interpretar datos cuantitativos. En su trabajo sobre pruebas de
hipótesis, desarrolló aplicaciones de la distribución F, por lo que lleva
su nombre. Esta distribución se utiliza para probar hipótesis acerca de
dos varían zas de pequeñas muestras. También la Z de Fisher usada para pro-
bar hipótesis acerca del coeficiente de correlación lineal.

J. Neyman (1894-
) y E. S. Pearson (1895- ) presentaron
una teoría de pruebas de hipótesis estadísticas en 1936 y 1938; esta teo-
ría promovió considerablemente la investigación y, muchos de sus resulta-
dos son de gran utilidad práctica.

William Feiler, nacido en 1906, contribuyó a la teoría de la pro
habilidad con su trabajo sobre el Teorema del Limite Central y las cadenas
de Markov. Introdujo un nuevo tratamiento en su libro "An Introduction to
Probability and its Aplications" (1961) que contiene muchos ejemplos que
explican nuevas aplicaciones a los fenómenos biológicos, físicos y estadis
ticos.

John von Neumann (1909-1957) llevó a cabo la primera demostra-
ción del teorema minimax, base fundamental de la teoría de juegos, que fue
propuesto primeramente por Emile Borel en 1921. También fue un pionero de
la teoría de las computadoras, habiendo diseñado y construido el llamado
MANIAC (analizador matemático, integrador numérico y computador) en e]
Instituto para Estudios Avanzados en Princeton en 19S2

Abraham Wald (1902-1950) en sus dos libros "Sequential Analysis"
y "Statistical Decision Fuctions" alcanzó grandes logros en Estadística y
sus aplicaciones.

Así, en este siglo es cuando se han desarrollado la mayoría de
los métodos estadísticos que se usan en la actualidad,

1.4 ESTADISTICA E INVESTIGACION

La Estadística interviene en la investigación y/o el método cien
tífico, a través de la experimentación y observación. Esto es, las observa-
ciones experimentales y conocimientos son partes integrantes del método
científico y esos métodos invariablemente conducen al empleo de técnicas de
la Estadística. Ya que la Estadística, cuando se usa adecuadamente, hace
más eficientes las investigaciones, es aconsejable que los investigadores
se familiaricen con las técnicas y conceptos básicos de esta ciencia tan
útil.

El uso de la estadística como herramienta de la investigación no
puede separarse de la planeación general del proyecto de investigación. Si
un proyecto de investigación debe producir datos que van a ser tratados es-
tadísticamente, entonces un método estadístico apropiado debe formar una
parte integrante del diseño total. Nada contribuye más a la angustia de un
estadístico que el investigador ingenuo que obtiene datos con la convicción
alegre de que un método estadístico estará automáticamente disponible para
ancalizarlos.

Aunque pueda parecer que está de más mencionarlo, un proyecto de
investigación debe ser diseñado y planificado antes de efectuarse. Sin em-
bargo, por muy evidente que parezca esto, los estadísticos conocen demasia-
do bien al investigador que aporta muchos datos, obtenidos de una manera for_
tuita y a menudo sin una idea precisa de por qué fueron obtenidos. En tales
casos, es a veces el triste deber del estadístico comunicarle al investiga-
dor que sus esfuerzos fueron desperdiciados porque no hay una manera legi-
tima de analizar sus datos.

1.5 ETAPAS DE UNA INVESTIGACION ESTADISTICA

1.- Formulación del problema: Para investigar con éxito un pro-
blema dado, primero tenemos que crear conceptos precisos, formular pregun
tas claras, e imponer limitaciones adecuadas al problema, tomando en cuen
ta el tiempo y el dinero disponibles y la habilidad de los investigado-
res. Si se fracasa en esta formulación, los datos compilados pueden ser
irrelevantes o inadecuados.

Es bueno rocordar que la calidad de las conclusiones estadísti-
cas depende de la corrección y precisión de los datos que, a su vez, de-
penden de la exactitud en la formulación del prohlema. Las técnicas esta-
dísticas, por muy refinadas y precisas que sean, no pueden ayudar a alcan
zar decisiones si son aplicadas a datos inapropiados.

2.- Diseño del experimento. Muestro deseo es obtener un máximo
de información empleando un mínimo de costo y tiempo. Esto implica, entre
otras cosas, que debemos determinar el tamaño de muestra, o la cantidad y
tipo de datos que resolverán más eficientemente el problema. A la vez, es
te tamaño sera afectado por el método matemático empleado en la última
etapa (5a. etapa), y tenemos que seleccionar este método al igual que uno
para muestrear. Con respecto al último, debemos observar que no es fácil
obtener selecciones que sean completamente aleatorias.

Obtener una muestra representativa es fundamental en teoría es-
tadística. Supone preguntas como estas: ¿Qué tipo de datos debe recogerse?
¿Cómo deben ser compilados los datos? ¿De qué tamaño debe ser la muestra?
Estas preguntas corresponden a lo que se conoce como diseño de muestras o
diseño experimental. Debe tenerse cuidado al planificar y diseñar un expe
rimento; de otro modo, puede que no lleguemos a alcanzar ninguna conclu-
sión válida.

3 . - Colección de datos y experimentación: La compilación de da-
tos se refiere a los métodos usados para obtener información pertinente de
las
unidades elementales introducidas en una muestra. Fin general, ésta es
la parte que más tiempo consume en toda investigación que sea realizada.
Esta debe sujetarse a reglas e s t r i c t a s . De hecho, cuanto menos opiniones
impongamos,
serán mejores los resultados

4 . - Tabulación y descripción de los resultados: En esta etapa
l o s datos experimentales deben ser ordenados en forma l e g i b l e y se i l u s -
t r a n con r e p r e s e n t a c i o n e s g r á f i c a s (diagramas o g r á f i c a s ) ; además se cal-cu
lan medidas d e s c r i p t i v a s para el tamaño promedio y la separación o d i s p e r -
sión de los v a l o r e s de la muestra. Los procedimientos c o r r e s p o n d i e n t e s son
simples y serán d i s c u t i d o s en la parte

5.- Ingererencia estadística formulación de
la
respuesta:
Al
a p l i c a r el método e s t a d í s t i c o seleccionado en la etapa 2. obtenemos conclu
siones a p a r t i r de la muestra, acerca de la población correspondiente (in-
ferencia e s t a d í s t i c a ) , tomamos una decisión y formulamos la respuesta a
nuest ro problema.

No e x i s t e una fórmula mágica en e s t a d í s t i c a matemática que tome
en cuenta todas las situaciones prácticas concebibles. Por lo cual es ne-
cesario a d q u i r i r conocimientos generales de los métodos más importantes
que sean ú t i l e s para hacer inferencias. En cada caso práctico debe estu-
diarse con cuidado la naturaleza del problema específico, para e s t a r segu-
ros de que será escogido el método más apropiado.

1.6 ESTADISTICA DESCRIPTIVA Y ESTADISTICA INFERENCIAL

Los datos t a l como se obtienen no nos proporcionan información
s u f i c i e n t e para i n t e r p r e t a r su significado por lo que tenemos que u t i l i z a r
métodos descriptivos para d a r l e s mayor sentido o inferenciales para sacar
conclusiones válidas sobre e l l o s . Estos métodos dependen del t i p o de datos
que se tengan y de los resultados que se quieran obtener

Los métodos descriptivos se emplean para esquematizar o mostrar
los datos en forma ordenada y gráfica sin sacar conclusiones de ellos. Los
métodos descriptivos se pueden usar tanto para muestras como para pobla-
ciones mientras que los métodos inferenciales usan solamente muestras para
inferir a partir de las primeras, las características de la población. Cuan
do usamos Estadística Inferencial generalizamos a partir de las Caracterís-
ticas de una muestra las de la población.

1.7 POBLACION Y MUESTRA

Una población o Universo es un agregado o la totalidad de unida-
des elementales tales como personas, empresas industriales, granjas o da-
tos de cualquier clase acerca de los cuales se desea información. Una mues
tra es una porción o subconjunto de unidades elementales extraídas de una
población.

1.8 UNIDADES ELEMENTALES Y OBSERVACION

Los individuos u objetos de una población que tienen una caracte_
rística medible se llaman unidades elementales; definir una población es,
en un sentido, limitar el contenido de las unidades elementales. Estas po-
seen ciertas características, conocidas a veces como rasgos o propiedades,
que pueden ser de naturaleza cualitativa o cuantitativa.

El término observación se usará para indicar cualquier clase de
medida obtenida en la investigación, es decir, el resultado de observar o
medir una unidad elemental, se llama observación; también se puede entender
como el valor numérico de una característica cuantificable de una unidad
elemental.

9. SUMATORIAS

Dado un conjunto de observaciones de alguna variable representada
por X1, X2,....,Xn , podemos expresar su suma X1+X2+....+Xn en forma abre-
viada como


Esto se lee " suma de los X. desde i igual a 1 hasta

Ejemplo 1.1
entonces
PROPIEDADES DE LAS SUMATORIAS
I.
Si c es una constante cualquiera, entonces
Demostración:

Ejemplo 1.2

enton
ces.
porque
Corolario:
Si
c
es una constante, entonces
9

SUMATORIAS DOBLES:
Frecuentemente en estadística se desea cono-
cer la interacción entre dos variables; asi por ejemplo, consideramos las
20 determinaciones de presión sanguínea sistólica tomadas a un individuo
que participa en un programa ideado para estudiar fuentes e intensidades
de variación de lecturas de la presión de la sangre. La presión de la san
gre fue medida por 4 médicos en cada una de 5 visitas. Los datos se resu-
men en la siguiente tabla.

Con el fin de ordenar linealmente estas dos clasificaciones, se uti_
liza un sistema de dos subíndices, esto es, se usa un subíndice para el núme_
ro de visita y otro para el número de médico. En tales situaciones es fre
cuente emplear las letras
i y j
para indicar el número de fila o rengl6n y
el número de columna,respectivamente. A cada observación se denota por X.-
que indica el dato en la i-ésima fila y j-ésima columna. En el conjunto de
datos anterior, X34 = 117, X32 = 120, etc.

Vamos a considerar ahora diversos tipos de sumas. Por ejemplo, la su
ma de los elementos de la segunda fila es
( fila 2, por tanto el primer subíndice queda fijo, solo
cambia la columna )

Para sumar todos los elementos de la tabla, se puede proceder de dos
maneras, primero sumar los elementos correspondientes a cada fila y luego ha-
llar la adición de estas sumas o sumar los elementos de cada columna y luego
sumar éstas.


Por filas tenemos:
que se pueden resumir así:


