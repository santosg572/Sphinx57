<!DOCTYPE html>

<html lang="sp" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>c02 Propositional Logic &#8212; документација Introduction_Artificial_Intel_3E 01</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=12dfc556" />
    <script src="_static/documentation_options.js?v=cb95fe6c"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Индекс" href="genindex.html" />
    <link rel="search" title="Претрага" href="search.html" />
    <link rel="prev" title="c01" href="c01.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="c02-propositional-logic">
<h1>c02 Propositional Logic<a class="headerlink" href="#c02-propositional-logic" title="Link to this heading">¶</a></h1>
<p>In propositional logic, as the name suggests, propositions are connected by logical operators. The statement “the street is wet” is a
proposition, as is “it is raining”. These two propositions can be connected to form the new proposition</p>
<p>if it is raining the street is wet.</p>
<p>Written more formally</p>
<p>it is raining ⇒ the street is wet.</p>
<p>This notation has the advantage that the elemental propositions appear again in unaltered form. So that we can work with propositional
logic precisely, we will begin with a deﬁnition of the set of all propositional logic formulas.</p>
<p><strong>2.1 Syntax</strong></p>
<p>Deﬁnition 2.1 Let Op = {¬, ∧, ∨, ⇒ , ⇐⇒ ,(,)} be the set of logical operators and Σ a set of symbols. The sets Op, Σ and {t, f }
are pairwise disjoint. Σ is called the signature and its elements are the proposition variables. The set of propositional logic
formulas is now recursively deﬁned:</p>
<ul class="simple">
<li><p>t and f are (atomic) formulas.</p></li>
<li><p>All proposition variables, that is all elements from Σ, are (atomic) formulas.</p></li>
</ul>
<ul class="simple">
<li><p>If A and B are formulas, then ¬A, (A), A ∧ B, A ∨ B, A ⇒ B, A B are ⇐⇒ also formulas.</p></li>
</ul>
<p>This elegant recursive deﬁnition of the set of all formulas allows us to generate inﬁnitely many formulas. For example, given Σ = {
A, B, C } ,</p>
<p>A ∧ B, A ∧ B ∧ C, A ∧ A ∧ A, C ∧ B ∨ A, (¬A ∧ B) ⇒ (¬C ∨ A)</p>
<p>are formulas. (((A)) ∨ B) is also a syntactically correct formula.</p>
<p><a href="#id1"><span class="problematic" id="id2">**</span></a>Deﬁnition 2.**2 We read the symbols and operators in the following way:</p>
<p>t: “true”
f : “false”
¬A: “not A”             (negation)
A ∧ B: “A and B”        (conjunction)
A ∨ B: “A or B” (disjunction)
A ⇒ B: “if A then B”   (implication (also called material implication))
A ⇔ B: “A if and onlyif B” (equivalence)</p>
<p>The formulas deﬁned in this way are so far purely syntactic constructions without meaning. We are still missing the semantics.</p>
<p><strong>2.2 Semantics</strong></p>
<p>In propositional logic, there are two truth values: t for “true” and f for “false”. We begin with an example and ask ourselves whether
the formula A ∧ B is true. The answer is: it depends on whether the variables A and B are true. For example, if A stands for “It is
raining today” and B for “It is cold today” and these are both true, then A ∧ B is true. If, however, B represents “It is hot today”
(and this is false), then A ∧ B is false.</p>
<p>We must obviously assign truth values that reﬂect the state of the world to proposition variables. Therefore, we deﬁne</p>
<p>Deﬁnition 2.3 A mapping I : Σ → { t, f } , which assigns a truth value to every proposition variable, is called an interpretation.</p>
<p>Because every proposition variable can take on two truth values, every propositional logic formula with n different variables has 2 n
different interpretations. We deﬁne the truth values for the basic operations by showing all possible interpretations in a truth
table (see Table 2.1).</p>
<p>The empty formula is true for all interpretations. In order to determine the truth value for complex formulas, we must also deﬁne the
order of operations for logical operators. If expressions are parenthesized, the term in the parentheses is evaluated ﬁrst. For
unparenthesized formulas, the priorities are ordered as follows, beginning with the strongest binding: ¬, ∧, ∨, ⇒ , ⇐⇒ .</p>
<p>To clearly differentiate between the equivalence of formulas and syntactic equivalence, we deﬁne</p>
<p><a href="#id3"><span class="problematic" id="id4">**</span></a>Deﬁnition 2.**4 Two formulas F and G are called semantically equivalent if they take on the same truth value for all
interpretations. We write F ≡ G.</p>
<p>Semantic equivalence serves above all to be able to use the meta-language, that is, natural language, to talk about the object
language, namely logic. The statement “A ≡ B” conveys that the two formulas A and B are semantically equivalent. The statement “A
⇐⇒ B”, on the other hand, is a syntactic object of the formal language of propositional logic.</p>
<p>According to the number of interpretations in which a formula is true, we can divide formulas into the following classes:</p>
<p><a href="#id5"><span class="problematic" id="id6">**</span></a>Deﬁnition 2.**5 A formula is called</p>
<ul class="simple">
<li><p>Satisﬁable if it is true for at least one interpretation.</p></li>
<li><p>Logically valid or simply valid if it is true for all interpretations. True formulas are also called tautologies.</p></li>
<li><p>Unsatisﬁable if it is not true for any interpretation.</p></li>
</ul>
<p>Every interpretation that satisﬁes a formula is called a model of the formula.</p>
<p>Clearly,thenegationofeverygenerallyvalidformulaisunsatisﬁable.Thenegation of a satisﬁable, but not generally valid formula F is
satisﬁable.</p>
<p>We are now able to create truth tables for complex formulas to ascertain their truth values. We put this into action immediately using
equivalences of formulas which are important in practice.</p>
<p><strong>Theorem 2.1</strong> The operations ∧, ∨ are commutative and associative, and the following equivalences are generally valid:</p>
<p>¬A ∨ B ⇔ A ⇒ B                  (implication)</p>
<p>A ⇒ B ⇔ ¬B ⇒ ¬A                 (contraposition)</p>
<p>(A ⇒ B) ∧ (B ⇒ A) ⇔ (A ⇔ B)     (equivalence)</p>
<p>¬(A ∧ B) ⇔ ¬A ∨                         (De Morgan’s law)</p>
<p>¬B ¬(A ∨ B) ⇔ ¬A ∧ ¬B</p>
<p>A ∨ (B ∧ C) ⇔ (A ∨ B) ∧ (A ∨ C) (distributive law)</p>
<p>A ∧ (B ∨ C) ⇔ (A ∧ B) ∨ (A ∧ C)</p>
<p>A ∨ ¬A ⇔                        (tautology)</p>
<p>w A ∧ ¬A ⇔ f                    (contradiction)</p>
<p>A∨f ⇔ A</p>
<p>A∨w ⇔ w</p>
<p>A∧f ⇔ f</p>
<p>A∧w ⇔ A</p>
<p><strong>2.3 Proof Systems</strong></p>
<p>In AI, we are interested in taking existing knowledge and from that deriving new knowledge or answering questions. In propositional
logic, this means showing that a knowledge base KB–that is, a (possibly extensive) propositional logic formulaa formula Q 1 follows.
Thus, we ﬁrst deﬁne the ter“entailment”.</p>
<p><a href="#id7"><span class="problematic" id="id8">**</span></a>Deﬁnition 2.**6 A formula KB entails a formula Q (or Q follows from KB) if every model of KB is also a model of Q. We write KB | =
Q.</p>
<p>In other words, in every interpretation in which KB is true, Q is also true. More succinctly, whenever KB is true, Q is also true.
Because, for the concept of entailment, interpretations of variables are brought in, we are dealing with a semantic concept.</p>
<p>Every formula that is not valid chooses so to speak a subset of the set of all interpretations as its model. Tautologies such as A ∨
¬A, for example, do not restrict the number of satisfying interpretations because their proposition is empty. The empty formula is
therefore true in all interpretations. For every tautology T, ∅ | = T . Intuitively, this means that tautologies are always true,
without restriction of the interpretations by a formula. For short, we write | = T . Now we show an important connection between the
semantic concept of entailment and syntactic implication.</p>
<p><strong>Theorem 2.2</strong> (Deduktionstheorem)</p>
<p>A | = B if and only if | = A ⇒ B.</p>
<p>If we wish to show that KB entails Q, we can also demonstrate by means of the truth table method that KB ⇒ Q is a tautology. Thus, we
have our ﬁrst proof system for propositional logic, which is easily automated. The disadvantage of this method is the very long
computation time in the worst case. Speciﬁcally, in the worst case
with n proposition variables, for all 2 n interpretations of the variables the formula KB ⇒ Q must be evaluated. The computation time
grows therefore exponentially with the number of variables. Therefore, this process is unusable for large variable counts, at least in
the worst case.</p>
<p>If a formula KB entails a formula Q, then, by the deduction theorem, KB ⇒ Q is a tautology. Therefore, the negation ¬(KB ⇒ Q) is
unsatisﬁable. We have</p>
<p>¬(KB ⇒ Q) ≡ ¬(¬KB ∨ Q) ≡ KB ∧ ¬Q.</p>
<p>Therefore, KB ∧¬ Q is also unsatisﬁable. We formulate this simple, but important consequence of the deduction theorem as a theorem.</p>
<p><strong>Theorem 2.3</strong> (Proof by contradiction) KB | = Q if and only if KB ∧¬ Q is unsatisﬁable.</p>
<p>To show that the query Q follows from the knowledge base KB, we can also add the negated query ¬Q to the knowledge base and derive a
contradiction. Because of the equivalence A ∧ ¬A ⇐⇒ f from Theorem 2.1, we know that a contradiction is unsatisﬁable. Therefore, Q
has been proved. This procedure, which is frequently used in mathematics, is also used in various automatic proof calculi such as the
resolution calculus and in the processing of PROLOG programs.</p>
<p>One way of avoiding having to test all interpretations with the truth table method is the syntactic manipulation of the formulas KB
and Q by application of inference rules with the goal of greatly simplifying them, such that, in the end, we can instantly see that KB
| = Q. We call this syntactic process derivation and write KB ⊢ Q. Such syntactic proof systems are called calculi. To ensure that a
calculus does not generate errors, we deﬁne two fundamental properties of calculi.</p>
<p><a href="#id9"><span class="problematic" id="id10">**</span></a>Deﬁnition 2.**7 A calculus is called sound if every derived proposition follows semantically. That is, if it holds for formulas KB
and Q that</p>
<p>if KB ⊢ Q then KB | = Q.</p>
<p>A calculus is called complete if all semantic consequences can be derived. That is, for formulas KB and Q, the following holds</p>
<p>if KB | = Q then KB ⊢ Q.</p>
<p>The soundness of a calculus ensures that all derived formulas are in fact semantic consequences of the knowledge base. The calculus
does not produce any “false consequences”. The completeness of a calculus, on the other hand, ensures that the calculus does not
overlook anything. A complete calculus always ﬁnds a proof if the formula to be proved follows from the knowledge base. If a calculus
is sound and complete, then syntactic derivation and semantic entailment are two equivalent relations (see Fig. 2.1).</p>
<p>Fig. 2.1 Syntactic derivation and semantic entailment. Mod(X) represents the set of models of a formula X</p>
<p>To keep automatic proof systems as simple as possible, these are usually made to operate on formulas in conjunctive normal form.</p>
<p><a href="#id11"><span class="problematic" id="id12">**</span></a>Deﬁnition 2.**8 A formula is in conjunctive normal form (CNF) if and only if it consists of a conjunction</p>
<p>K1 ∧K2 ∧···∧Km</p>
<p>of clauses. A clause K i consists of a disjunction</p>
<p>(L i1 ∨ L i2 ∨ · · · ∨ L in i )</p>
<p>of literals. Finally, a literal is a variable (positive literal) or a negated variable (negative literal).</p>
<p>The formula (A ∨ B ∨ ¬C) ∧ (A ∨ B) ∧ (¬B ∨ ¬C) is in conjunctive normal form. The conjunctive normal form does not place a
restriction on the set of formulas because:</p>
<p><strong>Theorem 2.4</strong> Every propositional logic formula can be transformed into an equivalent conjunctive normal form.</p>
<p><strong>Example 2.1</strong> We put A ∨ B ⇒ C ∧ D into conjunctive normal form by using the equivalences from Theorem 2.1:</p>
<p>A∨ B ⇒ C∧D</p>
<p>≡ ¬(A ∨ B) ∨ (C ∧ D)(implication)</p>
<p>≡ (¬A ∧ ¬B) ∨ (C ∧ D) (de Morgan)</p>
<p>≡ (¬A ∨ (C ∧ D)) ∧ (¬B ∨ (C ∧ D)) (distributive law)</p>
<p>≡ ((¬A ∨ C) ∧ (¬A ∨ D)) ∧ ((¬B ∨ C) ∧ (¬B ∨ D))(distributive law)</p>
<p>≡ (¬A ∨ C) ∧ (¬A ∨ D) ∧ (¬B ∨ C) ∧ (¬B ∨ D)(associative law)</p>
<p>We are now only missing a calculus for syntactic proof of propositional logic formulas. We start with the modus ponens, a simple,
intuitive rule of inference, which, from the validity of A and A ⇒ B, allows the derivation of B. We write this formally as</p>
<p>A, A ⇒ B . B</p>
<p>This notation means that we can derive the formula(s) below the line from the commaseparated formulas above the line. Modus ponens as
a rule by itself, while sound, is not complete. If we add additional rules, we can create a complete calculus, which, however, we do
not wish to consider here. Instead, we will investigate the resolution rule</p>
<p>A ∨ B, ¬B ∨ C A∨C</p>
<p>(2.1)</p>
<p>as an alternative. The derived clause is called resolvent. Through a simple transformation, we obtain the equivalent form</p>
<p>A ∨ B, B ⇒ C . A∨C</p>
<p>If we set A to f, we see that the resolution rule is a generalization of the modus ponens. The resolution rule is equally usable if C
is missing or if A and C are missing. In the latter case, the empty clause can be derived from the contradiction B ∧ ¬B (Exercise 3).</p>
<p>2.4 Resolution</p>
<p>We now generalize the resolution rule again by allowing clauses with an arbitrary number of literals. With the literals A 1 , …, A m ,
B, C 1 , …, C n the general resolution rule reads</p>
<p>(A 1 ∨ · · · ∨ A m ∨ B), (¬B ∨ C 1 ∨ · · · ∨ C n ) . (A 1 ∨ · · · ∨ A m ∨ C 1 ∨ · · · ∨ C n )</p>
<p>(2.2)</p>
<p>We call the literals B and ¬B complementary. The resolution rule deletes a pair of complementary literals from the two clauses and
combines the rest of the literals into a new clause.</p>
<p>To prove that from a knowledge base KB, a query Q follows, we carry out a proof by contradiction. Following Theorem 2.3, we must show
that a contradiction can be derived from KB ∧ ¬Q. In formulas in conjunctive normal form, a contradiction appears in the form of two
clauses (A) and (¬A), which leads to the empty clause as their resolvent. The following theorem ensures us that this process really
works as desired.</p>
<p>For the calculus to be complete, we need a small addition, as shown by the following example. Let the formula (A ∨ A) be given as our
knowledge base. To show by the resolution rule that from there we can derive (A ∧ A), we must show that</p>
<p>the empty clause can be derived from (A ∨ A) ∧ (¬A ∨ ¬A). With the resolution rule alone, this is impossible. With factorization,
which allows deletion of copies of literals from clauses, this problem is eliminated. In the example, a double application of
factorization leads to (A) ∧ (¬A), and a resolution step to the empty clause.</p>
<p>Theorem 2.5 The resolution calculus for the proof of unsatisﬁability of formulas in conjunctive normal form is sound and complete.</p>
<p>Because it is the job of the resolution calculus to derive a contradiction from KB ∧ ¬Q, it is very important that the knowledge base
KB is consistent:</p>
<p>Deﬁnition 2.9 A formula KB is called consistent if it is impossible to derive from it a contradiction, that is, a formula of the form
φ ∧ ¬φ.</p>
<p>Otherwise, anything can be derived from KB (see Exercise 4). This is true not only of resolution but also for many other calculi.</p>
<p>Of the calculi for automated deduction, resolution plays an exceptional role. Thus, we wish to work a bit more closely with it. In
contrast to other calculi, resolution has only two inference rules, and it works with formulas in conjunctive normal form. This makes
its implementation simpler. A further advantage compared to many calculi lies in its reduction in the number of possibilities for the
application of inference rules in every step of the proof, whereby the search space is reduced and computation time decreased.</p>
<p>As an example, we start with a simple logic puzzle that allows the important steps of a resolution proof to be shown.</p>
<p>Example 2.2 Logic puzzle number 7, entitled A charming English family, from the German book [Ber89] reads (translated to English):</p>
<p>Despite studying English for seven long years with brilliant success, I must admit that when I hear English people speaking English
I’m totally perplexed. Recently, moved by noble feelings, I picked up three hitchhikers, a father, mother, and daughter, who I quickly
realized were English and only spoke English. At each of the sentences that follow I wavered between two possible interpretations.
They told me the following (the second possible meaning is in parentheses): The father: “We are going to Spain (we are from
Newcastle).” The mother: “We are not going to Spain and are from Newcastle (we stopped in Paris and are not going to Spain).” The
daughter: “We are not from Newcastle (we stopped in Paris).” What about this charming English family?</p>
<p>To solve this kind of problem, we proceed in three steps: formalization, transformation into normal form, and proof. In many cases,
formalization is by far the most difﬁcult step because it is easy to make mistakes or forget small details. (Thus practical exercise
is very important. See Exercises 2.9–2.11.)</p>
<p>Here we use the variables S for “We are going to Spain”, N for “We are from Newcastle”, and P for “We stopped in Paris” and obtain as
a formalization of the three propositions of father, mother, and daughter</p>
<p>(S ∨ N) ∧ [ (¬S ∧ N) ∨ (P ∧ ¬S) ] ∧ (¬N ∨ P).</p>
<p>Factoring out ¬S in the middle sub-formula brings the formula into CNF in one step. Numbering the clauses with subscripted indices
yields</p>
<p>KB ≡ (S ∨ N) 1 ∧ (¬S) 2 ∧ (P ∨ N) 3 ∧ (¬N ∨ P) 4 .</p>
<p>Now we begin the resolution proof, at ﬁrst still without a query Q. An expression of the form “Res(m, n): 〈 clause 〉 k ” means that
〈 clause 〉 is obtained by resolution of clause m with clause n and is numbered k.</p>
<p>Res(1, 2): (N)5  Res(3, 4): (P)6  Res(1, 4): (S ∨ P)7</p>
<p>We could have derived clause P also from Res(4, 5) or Res(2, 7). Every further resolution step would lead to the derivation of clauses
that are already available. Because it does not allow the derivation of the empty clause, it has therefore been shown that the
knowledge base is non-contradictory. So far, we have derived N and P. To show that ¬S holds, we add the clause (S) 8 to the set of
clauses as a negated query. With the resolution step</p>
<p>Res(2, 8) : ()9</p>
<p>the proof is complete. Thus, ¬S ∧ N ∧ P holds. The “charming English family” evidently comes from Newcastle, stopped in Paris, but
is not going to Spain.</p>
<p>Example 2.3 Logic puzzle number 28 from [Ber89], entitled The High Jump, reads</p>
<p>Three girls practice high jump for their physical education ﬁnal exam. The bar is set to 1.20 meters. “I bet”, says the ﬁrst girl to
the second, “that I will make it over if, and only if, you don’t”. If the second girl said the same to the third, who in turn said the
same to the ﬁrst, would it be possible for all three to win their bets?</p>
<p>We show through proof by resolution that not all three can win their bets. Formalization:</p>
<p>The ﬁrst girl’s jump succeeds:A, First girl’s bet: (A ⇔ ¬B) , the second girl’s jump succeeds:B, second girl’s bet: (B ⇔ ¬C) , the
third girl’s jump succeeds: C. third girl’s bet: (C ⇔ ¬A) .</p>
<p>Claim: the three cannot all win their bets:</p>
<p>Q ≡ ¬((A ⇔ ¬B) ∧ (B ⇔ ¬C) ∧ (C ⇔ ¬A))</p>
<p>It must now be shown by resolution that ¬Q is unsatisﬁable. Transformation into CNF: First girl’s bet:</p>
<p>(A ⇔ ¬B) ≡ (A ⇒ ¬B) ∧ (¬B ⇒ A) ≡ (¬A ∨ ¬B) ∧ (A ∨ B)</p>
<p>The bets of the other two girls undergo analogous transformations, and we obtain the negated claim</p>
<p>¬Q ≡ (¬A ∨ ¬B) 1 ∧ (A ∨ B) 2 ∧ (¬B ∨ ¬C) 3 ∧ (B ∨ C) 4 ∧ (¬C ∨ ¬A)5</p>
<p>∧ (C ∨ A) 6 .</p>
<p>From there, we derive the empty clause using resolution:</p>
<p>Res(1, 6) : (C ∨ ¬B)7</p>
<p>Res(4, 7) :</p>
<p>(C)8</p>
<p>Res(2, 5) : (B ∨ ¬C)9</p>
<p>Res(3, 9) : Res(8, 10) :</p>
<p>(¬C)10  ()</p>
<p>Thus the claim has been proved.</p>
<p>2.5 Horn Clauses</p>
<p>A clause in conjunctive normal form contains positive and negative literals and can be represented in the form</p>
<p>(¬A 1 ∨ · · · ∨ ¬A m ∨ B 1 ∨ · · · ∨ B n )</p>
<p>with the variables A 1 , . . . , A m and B 1 , . . . , B n . This clause can be transformed in two simple steps into the equivalent
form</p>
<p>A1 ∧···∧ A m ⇒ B1 ∨···∨ Bn .</p>
<p>This implication contains the premise, a conjunction of variables, and the conclusion, a disjunction of variables. For example, “If
the weather is nice and there is snow on the ground, I will go skiing or I will work.” is a proposition of this form. The receiver of
this message knows for certain that the sender is not going swimming. A signiﬁcantly clearer statement would be “If the weather is
nice and there is snow on the ground, I will go skiing.” The receiver now has deﬁnite information. Thus, we call clauses with at most
one positive literal deﬁnite clauses. These clauses have the advantage that they only allow one conclusion and are thus distinctly
simpler to interpret. Many relations can be described by clauses of this type. We therefore deﬁne</p>
<p>Deﬁnition 2.10 Clauses with at most one positive literal of the form</p>
<p>(¬A 1 ∨ · · · ∨ ¬A m ∨ B) or (¬A 1 ∨ · · · ∨ ¬A m ) or B</p>
<p>or (equivalently)</p>
<p>A 1 ∧ · · · ∧ A m ⇒ B or A 1 ∧ · · · ∧ A m ⇒ f or B.</p>
<p>are named Horn clauses (after their inventor). A clause with a single positive literal is a fact. In clauses with negative literals
and on positive literal, the positive literal is called the head.</p>
<p>To better understand the representation of Horn clauses, the reader may derive them from the deﬁnitions of the equivalences we have
currently been using (Exercise 2.12).</p>
<p>Horn clauses are easier to handle not only in daily life but also in formal reasoning, as we can see in the following example. Let the
knowledge base consist of the following clauses (the “∧ ′′ binding the clauses is left out here and in the text that follows):</p>
<p>(nice_weather)1  (snowf all)2  (snowf all ⇒ snow)3  (nice_weather ∧ snow ⇒ skiing)4</p>
<p>If we now want to know whether skiing holds, this can easily be derived. A slightly generalized modus ponens sufﬁces here as an
inference rule:</p>
<p>A1 ∧···∧ Am ,A1 ∧···∧ A m ⇒ B . B</p>
<p>The proof of “skiing” has the following form (MP(i 1 , . . . , i k ) represents application of the modus ponens on clauses i 1 to i k
:</p>
<p>MP(2, 3) : (snow)5  MP(1, 5, 4) : (skiing) 6 .</p>
<p>With modus ponens, we obtain a complete calculus for formulas that consist of propositional logic Horn clauses. In the case of large
knowledge bases, however, modus ponens can derive many unnecessary formulas if one begins with the wrong clauses. Therefore, in many
cases, it is better to use a calculus that starts with the query and works backward until the facts are reached. Such systems are
designated backward chaining, in contrast to forward chaining systems, which start with facts and ﬁnally derive the query, as in the
above example with the modus ponens.</p>
<p>For backward chaining of Horn clauses, SLD resolution is used. SLD stands for “Selection rule driven linear resolution for deﬁnite
clauses”. In the above example, augmented by the negated query (skiing ⇒ f)</p>
<p>(nice_weather)1  (snowf all)2  (snowf all ⇒ snow)3  (nice_weather ∧ snow ⇒ skiing)4</p>
<p>(skiing ⇒ f )5</p>
<p>we carry out SLD resolution beginning with the resolution steps that follow from this clause</p>
<p>Res(5, 4): (nice_weather ∧ snow ⇒ f )6  Res(6, 1): (snow ⇒ f )7  Res(7, 3): (snowf all ⇒ f )8  Res(8, 2): ()</p>
<p>and derive a contradiction with the empty clause. Here we can easily see “linear resolution”, which means that further processing is
always done on the currently derived clause. This leads to a great reduction of the search space. Furthermore, the literals of the
current clause are always processed in a ﬁxed order (for example, from right to left) (“Selection rule driven”). The literals of the
current clause are called subgoal. The literals of the negated query are the goals. The inference rule for one step reads</p>
<p>A1 ∧···∧ A m ⇒ B1 ,B1 ∧ B2 ∧···∧ B n ⇒ f . A1 ∧···∧ A m ∧ B2 ∧···∧ B n ⇒ f</p>
<p>Before application of the inference rule, B 1 , B 2 , . . . , B n – the current subgoals–must be proved. After the application, B 1 is
replaced by the new subgoal A 1 ∧ · · · ∧ A m . To show that B 1 is true, we must now show that A 1 ∧ · · · ∧ A m are true. This
process continues until the list of subgoals of the current clauses (the so-called goal stack) is empty. With that, a contradiction
has been found. If, for a subgoal ¬B i , there is no clause with the complementary literal B i as its clause head, the proof
terminates and no contradiction can be found. The query is thus unprovable.</p>
<p>SLD resolution plays an important role in practice because programs in the logic programming language PROLOG consist of predicate
logic Horn clauses and their processing is achieved by means of SLD resolution (see Exercise 2.13, or Chap. 5).</p>
<p>2.6 Computability and Complexity</p>
<p>The truth table method, as the simplest semantic proof system for propositional logic, represents an algorithm that can determine
every model of any formula in ﬁnite time. Thus the sets of unsatisﬁable, satisﬁable, and valid formulas are decidable. The
computation time of the truth table method for satisﬁability grows in the worst case exponentially with the number n of variables
because the truth table has 2 n rows. An optimization, the method of semantic trees, avoids looking at variables that do not</p>
<p>occur in clauses, and thus saves computation time in many cases, but in the worst case it is likewise exponential.</p>
<p>In resolution, in the worst case, the number of derived clauses grows exponentially with the number of initial clauses. To decide
between the two processes, we can therefore use the rule of thumb that in the case of many clauses with few variables, the truth table
method is preferable, and in the case of few clauses with many variables, resolution will probably ﬁnish faster.</p>
<p>The question remains: can proof in propositional logic go faster? Are there better algorithms? The answer: probably not. After all, S.
Cook, the founder of complexity theory, has shown that the 3-SAT problem is NP-complete. 3-SAT is the set of all CNF formulas whose
clauses have exactly three literals. Thus, it is clear that there is probably (modulo the P/NP problem) no polynomial algorithm for
3-SAT, and thus probably not a general one either. For Horn clauses, however, there is an algorithm in which the computation time for
testing satisﬁability grows only linearly as the number of literals in the formula increases.</p>
<p>2.7 Applications and Limitations</p>
<p>Theoremproversforpropositionallogicarepartofthedeveloper’severydaytoolsetin digital technology. For example, the veriﬁcation of
digital circuits and the generation of test patterns for testing of microprocessors in fabrication are some of these tasks. Special
proof systems that work with binary decision diagrams (BDD) are also employed as a data structure for processing propositional logic
formulas.</p>
<p>In AI, propositional logic is employed in simple applications. For example, simple expert systems can certainly work with
propositional logic. However, the variables must all be discrete, with only a few values, and there may not be any cross-relations
between variables. Complex logical connections can be expressed much more elegantly using predicate logic.</p>
<p>Probabilistic logic is a very interesting and current combination of propositional logic and probabilistic computation that allows
modeling of uncertain knowledge. It is handled thoroughly in Chap. 7.</p>
<p>2.8 Exercises</p>
<p>➳ Exercise 2.1 logic.</p>
<p>Give a Backus–Naur form grammar for the syntax of propositional</p>
<p>Exercise 2.2 Show that the following formulas are tautologies:</p>
<ol class="loweralpha simple">
<li><p>¬(A ∧ B) ⇐⇒ ¬A ∨ ¬B (b) A ⇒ B ⇐⇒ ¬B ⇒ ¬A</p></li>
</ol>
<ol class="loweralpha simple" start="3">
<li><p>((A ⇒ B) ∧ (B ⇒ A)) ⇐⇒ (A ⇐⇒ B)</p></li>
<li><p>(A ∨ B) ∧ (¬B ∨ C) ⇒ (A ∨ C)</p></li>
</ol>
<p>Exercise 2.3 Transform the following formulas into conjunctive normal form:</p>
<ol class="loweralpha simple">
<li><p>A ⇐⇒ B</p></li>
<li><p>A ∧ B ⇐⇒ A ∨ B</p></li>
<li><p>A ∧ (A ⇒ B) ⇒ B</p></li>
</ol>
<p>Exercise 2.4 Check the following statements for satisﬁability or validity.</p>
<ol class="loweralpha simple">
<li><p>(play_lottery ∧ six_right) ⇒ winner</p></li>
<li><p>(play_lottery ∧ six_right ∧ (six_right ⇒ win)) ⇒ win</p></li>
<li><p>¬(¬gas_in_tank ∧ (gas_in_tank ∨ ¬car_starts) ⇒ ¬car_starts)</p></li>
</ol>
<p>❄ ❄ Exercise 2.5 Using the programming language of your choice, program a theorem prover for propositional logic using the truth
table method for formulas in conjunctive normal form. To avoid a costly syntax check of the formulas, you may represent clauses as
lists or sets of literals, and the formulas as lists or sets of clauses. The program should indicate whether the formula is
unsatisﬁable, satisﬁable, or true, and output the number of different interpretations and models.</p>
<p>Exercise 2.6</p>
<ol class="loweralpha simple">
<li><p>Show that modus ponens is a valid inference rule by showing that A ∧ (A ⇒</p></li>
</ol>
<ol class="upperalpha" start="2">
<li><div class="line-block">
<div class="line">= B.</div>
</div>
</li>
</ol>
<ol class="loweralpha simple" start="2">
<li><p>Show that the resolution rule (2.1) is a valid inference rule.</p></li>
</ol>
<p>❄ Exercise 2.7 Show by application of the resolution rule that, in conjunctive normal form, the empty clause is equivalent to the
false statement.</p>
<p>❄ Exercise 2.8 Show that, with resolution, one can “derive” any arbitrary clause from a knowledge base that contains a contradiction.</p>
<p>Exercise 2.9 Formalize the following logical functions with the logical operators and show that your formula is valid. Present the
result in CNF.</p>
<ol class="loweralpha simple">
<li><p>The XOR operation (exclusive or) between two variables.</p></li>
<li><p>The statement at least two of the three variables A, B, C are true.</p></li>
</ol>
<p>❄ Exercise 2.10 Solve the following case with the help of a resolution proof: “If the criminal had an accomplice, then he came in a
car. The criminal had no accomplice</p>
<p>and did not have the key, or he had the key and an accomplice. The criminal had the key. Did the criminal come in a car or not?”</p>
<p>Exercise 2.11 Show by resolution that the formula from</p>
<ol class="loweralpha simple">
<li><p>Exercise 2.2(d) is a tautology.</p></li>
<li><p>Exercise 2.4(c) is unsatisﬁable.</p></li>
</ol>
<p>Exercise 2.12 Prove the following equivalences, which are important for working with Horn clauses:</p>
<ol class="loweralpha simple">
<li><p>(¬A 1 ∨ · · · ∨ ¬A m ∨ B) ≡ A 1 ∧ · · · ∧ A m ⇒ B (b) (¬A 1 ∨ · · · ∨ ¬A m ) ≡ A 1 ∧ · · · ∧ A m ⇒ f (c) A ≡ w ⇒ A</p></li>
</ol>
<p>Exercise 2.13 Show by SLD resolution that the following Horn clause set is unsatisﬁable.</p>
<ol class="upperalpha simple">
<li><p>1 (D)4</p></li>
<li><p>2 (E)5</p></li>
</ol>
<p>(A</p>
<p>∧</p>
<p>D</p>
<p>⇒</p>
<p>G)7</p>
<p>(C</p>
<p>∧</p>
<p>F</p>
<p>∧</p>
<p>E</p>
<p>⇒</p>
<p>H)8</p>
<ol class="upperalpha simple" start="3">
<li><p>3 (A ∧ B ∧ C ⇒ F) 6 (H ⇒ f )9</p></li>
</ol>
<p>➳ Exercise 2.14 In Sect. 2.6, it says: “Thus it is clear that there is probably (modulo the P/NP problem) no polynomial algorithm for
3-SAT, and thus probably not a general one either.” Justify the “probably” in this sentence.</p>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">Introduction_Artificial_Intel_3E</a></h1>








<h3>Навигација</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="c01.html">c01</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">c02 Propositional Logic</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="c01.html" title="претходна глава">c01</a></li>
  </ul></li>
</ul>
</div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Брза претрага</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Тражи" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2026, Leopoldo.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.4.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="_sources/c02.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>